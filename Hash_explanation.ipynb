{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ4NO87VAG5D7jc380oivA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajarajeswarir/Hands-on-Machine-Learning/blob/main/Hash_explanation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Improve the train-test split with the hashing function**\n",
        "\n",
        "\n",
        "https://towardsdatascience.com/improve-the-train-test-split-with-the-hashing-function-f38f32b721fb"
      ],
      "metadata": {
        "id": "O4m9i33eM19z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTMyfC8KMzBo",
        "outputId": "159fab33-ba8e-4674-929d-0ee2fd0b8bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 669\n",
            "Test set: 59\n"
          ]
        }
      ],
      "source": [
        "# import the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from zlib import crc32\n",
        "\n",
        "# generate the first DataFrame\n",
        "X_1 = pd.DataFrame(data={\"variable\": np.random.normal(size=1000)})\n",
        "\n",
        "# apply the train-test split\n",
        "X_1_train, X_1_test = train_test_split(X_1, test_size=0.2, random_state=42)\n",
        "\n",
        "# add new observations to the DataFrame\n",
        "X_2 = pd.concat([X_1, pd.DataFrame(data={\"variable\": np.random.normal(size=500)})]).reset_index(drop=True)\n",
        "\n",
        "# again, apply the train-test split to the updated DataFrame\n",
        "X_2_train, X_2_test = train_test_split(X_2, test_size=0.2, random_state=42)\n",
        "\n",
        "# see what is the overlap of indices\n",
        "print(f\"Train set: {len(set(X_1_train.index).intersection(set(X_2_train.index)))}\")\n",
        "print(f\"Test set: {len(set(X_1_test.index).intersection(set(X_2_test.index)))}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hashed_train_test_split(df, index_col, test_size=0.2):\n",
        "    \"\"\"\n",
        "    Train-test split based on the hash of the unique identifier.\n",
        "    \"\"\"\n",
        "    test_index = df[index_col].apply(lambda x: crc32(np.int64(x)))\n",
        "    test_index = test_index < test_size * 2**32\n",
        "\n",
        "    return df.loc[~test_index], df.loc[test_index]"
      ],
      "metadata": {
        "id": "W7pgiDFyNE34"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an index column (should be immutable and unique)\n",
        "X_1 = X_1.reset_index(drop=False)\n",
        "X_2 = X_2.reset_index(drop=False)\n",
        "\n",
        "# apply the improved train-test split\n",
        "X_1_train_hashed, X_1_test_hashed = hashed_train_test_split(X_1, \"index\")\n",
        "X_2_train_hashed, X_2_test_hashed = hashed_train_test_split(X_2, \"index\")\n",
        "\n",
        "# see what is the overlap of indices\n",
        "print(f\"Train set: {len(set(X_1_train_hashed.index).intersection(set(X_2_train_hashed.index)))}\")\n",
        "print(f\"Test set: {len(set(X_1_test_hashed.index).intersection(set(X_2_test_hashed.index)))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND0tYYsiNxMq",
        "outputId": "e24b8079-db1d-4fa9-b2a7-925d74b4e53f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 800\n",
            "Test set: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZoHFPnRxOHxm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}